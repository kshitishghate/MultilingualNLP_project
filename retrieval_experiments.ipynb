{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kshitishghate/miniforge3/envs/mnlp-assgn-2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Icon\\r'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = \"CFD-INDIA\"\n",
    "indian_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "indian_names.sort()\n",
    "indian_names.pop(0)\n",
    "indian_names.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indian_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model_m = SentenceTransformer('sentence-transformers/clip-ViT-B-32-multilingual-v1')\n",
    "clip_model = SentenceTransformer('clip-ViT-B-32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:16<00:00,  8.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"CFD-INDIA\"\n",
    "\n",
    "training_image_path = []\n",
    "training_image_emb = []\n",
    "\n",
    "# Loop over all images in the subdirectory\n",
    "for name in tqdm(indian_names):\n",
    "    # Get the full path to the current image\n",
    "    image_full_path = os.path.join(dir_path, name)\n",
    "    # Open the image and append it to training_image_pil\n",
    "    try:\n",
    "        image_pil = Image.open(image_full_path)\n",
    "        # processed_img = process_image(image_full_path,image_size,device='cpu')\n",
    "    except (UnidentifiedImageError,FileNotFoundError):\n",
    "        continue\n",
    "    # training_image_pil.append(image_pil)\n",
    "    image_emb = clip_model.encode([image_pil])\n",
    "    training_image_emb.append(image_emb)\n",
    "    training_image_path.append(image_full_path)\n",
    "\n",
    "fileObj = open(f'indian_embeddings.obj', 'wb')\n",
    "pickle.dump(training_image_emb,fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open(f'indian_embeddings_path.obj', 'wb')\n",
    "pickle.dump(training_image_path,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "indian_image_embs = pd.read_pickle(\"indian_embeddings.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indian_image_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"indian-image-norms.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>EthnicitySelf</th>\n",
       "      <th>GenderSelf</th>\n",
       "      <th>AgeSelf</th>\n",
       "      <th>AgeRated</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>FemaleProb</th>\n",
       "      <th>MaleProb</th>\n",
       "      <th>AsianProb</th>\n",
       "      <th>ChineseAsianProb</th>\n",
       "      <th>...</th>\n",
       "      <th>MothersAncestorsState</th>\n",
       "      <th>MothersAncestorsPSU</th>\n",
       "      <th>MothersAncestorsPIN</th>\n",
       "      <th>FathersAncestorsCity</th>\n",
       "      <th>FathersAncestorsState</th>\n",
       "      <th>FathersAncestorsPSU</th>\n",
       "      <th>FathersAncestorsPIN</th>\n",
       "      <th>HighestDegree</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>HouseholdIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IF601-519</td>\n",
       "      <td>I</td>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>6.422751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IF602-134</td>\n",
       "      <td>I</td>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.736842</td>\n",
       "      <td>4.163446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IF605-066</td>\n",
       "      <td>I</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43.968750</td>\n",
       "      <td>7.346205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IF608-390</td>\n",
       "      <td>I</td>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.027778</td>\n",
       "      <td>5.891816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IF609-408</td>\n",
       "      <td>I</td>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>52.851852</td>\n",
       "      <td>7.548325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model EthnicitySelf GenderSelf  AgeSelf   AgeRated  Unnamed: 5  \\\n",
       "0  IF601-519             I          F     34.0  32.300000    6.422751   \n",
       "1  IF602-134             I          F     21.0  25.736842    4.163446   \n",
       "2  IF605-066             I          F     49.0  43.968750    7.346205   \n",
       "3  IF608-390             I          F     22.0  22.027778    5.891816   \n",
       "4  IF609-408             I          F     50.0  52.851852    7.548325   \n",
       "\n",
       "   FemaleProb  MaleProb  AsianProb  ChineseAsianProb  ...  \\\n",
       "0         1.0       0.0        NaN          0.000000  ...   \n",
       "1         1.0       0.0        NaN          0.000000  ...   \n",
       "2         1.0       0.0        NaN          0.031250  ...   \n",
       "3         1.0       0.0        NaN          0.000000  ...   \n",
       "4         1.0       0.0        NaN          0.037037  ...   \n",
       "\n",
       "   MothersAncestorsState  MothersAncestorsPSU  MothersAncestorsPIN  \\\n",
       "0                    NaN                  NaN                  NaN   \n",
       "1                    NaN                  NaN                  NaN   \n",
       "2                    NaN                  NaN                  NaN   \n",
       "3                    NaN                  NaN                  NaN   \n",
       "4                    NaN                  NaN                  NaN   \n",
       "\n",
       "   FathersAncestorsCity  FathersAncestorsState  FathersAncestorsPSU  \\\n",
       "0                   NaN                    NaN                  NaN   \n",
       "1                   NaN                    NaN                  NaN   \n",
       "2                   NaN                    NaN                  NaN   \n",
       "3                   NaN                    NaN                  NaN   \n",
       "4                   NaN                    NaN                  NaN   \n",
       "\n",
       "   FathersAncestorsPIN  HighestDegree  Occupation  HouseholdIncome  \n",
       "0                  NaN            NaN         NaN              NaN  \n",
       "1                  NaN            NaN         NaN              NaN  \n",
       "2                  NaN            NaN         NaN              NaN  \n",
       "3                  NaN            NaN         NaN              NaN  \n",
       "4                  NaN            NaN         NaN              NaN  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_female_images = indian_image_embs[:52]\n",
    "indian_male_images = indian_image_embs[52:104]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Image retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits = pd.read_csv(\"hindi_traits.csv\", header=None)\n",
    "traits_en = traits[0].tolist()\n",
    "traits_hi = traits[1].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00, 15.76it/s]\n"
     ]
    }
   ],
   "source": [
    "retrieval_text_emb_en = clip_model_m.encode(traits_en, show_progress_bar=True)\n",
    "retrieval_text_emb_hi = clip_model_m.encode(traits_hi, show_progress_bar=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieval_text_emb = clip_model_m.encode(\"A face of a beautiful person\", show_progress_bar=True)\n",
    "indian_image_emb = np.array(indian_image_embs[:104])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'male': 18, 'female': 32}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retrieval_text_emb = np.array(clip_model_m.encode(\"abusive\", show_progress_bar=True))\n",
    "# indian_image_emb = np.array(indian_image_embs[:104])\n",
    "retrieval_counts = {}\n",
    "# for i, retrieval_emb in tqdm(enumerate(retrieval_text_emb)):\n",
    "    # Calculate cosine similarity between the retrieval text embedding and all image embeddings\n",
    "similarities = cosine_similarity(retrieval_text_emb.reshape(1, -1), indian_image_emb.squeeze())\n",
    "\n",
    "# Sort the similarities and get the indices of the closest embeddings\n",
    "# closest_indices = np.argsort(similarities[0])[::-1][:1000] #(for 2b)\n",
    "closest_indices = np.argsort(similarities[0])[::-1][:50] #(for 2a)\n",
    "\n",
    "# Count the number of retrievals for each identity individually\n",
    "counts = {\n",
    "    'male': 0,\n",
    "    'female': 0,\n",
    "}\n",
    "\n",
    "# Iterate over the closest indices and count the intersectional identities\n",
    "for index in closest_indices:\n",
    "    if index < len(indian_female_images):\n",
    "        counts['female'] += 1\n",
    "    else:\n",
    "        counts['male'] += 1\n",
    "\n",
    "\n",
    "# Store the counts in the retrieval_counts dictionary\n",
    "retrieval_counts[0] = counts\n",
    "retrieval_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(retrieval_text_emb, indian_image_emb):\n",
    "    retrieval_text_emb = np.array(retrieval_text_emb)\n",
    "    # indian_image_emb = np.array(indian_image_embs[:104])\n",
    "    retrieval_counts = {}\n",
    "    for i, retrieval_emb in tqdm(enumerate(retrieval_text_emb)):\n",
    "        # Calculate cosine similarity between the retrieval text embedding and all image embeddings\n",
    "        similarities = cosine_similarity(retrieval_emb.reshape(1, -1), indian_image_emb.squeeze())\n",
    "\n",
    "        # Sort the similarities and get the indices of the closest embeddings\n",
    "        # closest_indices = np.argsort(similarities[0])[::-1][:1000] #(for 2b)\n",
    "        closest_indices = np.argsort(similarities[0])[::-1][:50] #(for 2a)\n",
    "\n",
    "        # Count the number of retrievals for each identity individually\n",
    "        counts = {\n",
    "            'male': 0,\n",
    "            'female': 0,\n",
    "        }\n",
    "\n",
    "        # Iterate over the closest indices and count the intersectional identities\n",
    "        for index in closest_indices:\n",
    "            if index < len(indian_female_images):\n",
    "                counts['female'] += 1\n",
    "            else:\n",
    "                counts['male'] += 1\n",
    "\n",
    "\n",
    "        # Store the counts in the retrieval_counts dictionary\n",
    "        retrieval_counts[i] = counts\n",
    "    return retrieval_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [00:00, 823.60it/s]\n",
      "54it [00:00, 2457.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assuming indian_image_emb, indian_female_images are defined\n",
    "scores_en = get_scores(retrieval_text_emb_en, indian_image_emb)\n",
    "scores_hi = get_scores(retrieval_text_emb_hi, indian_image_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'male': 22, 'female': 28},\n",
       " 1: {'male': 27, 'female': 23},\n",
       " 2: {'male': 28, 'female': 22},\n",
       " 3: {'male': 34, 'female': 16},\n",
       " 4: {'male': 30, 'female': 20},\n",
       " 5: {'male': 31, 'female': 19},\n",
       " 6: {'male': 30, 'female': 20},\n",
       " 7: {'male': 26, 'female': 24},\n",
       " 8: {'male': 26, 'female': 24},\n",
       " 9: {'male': 33, 'female': 17},\n",
       " 10: {'male': 36, 'female': 14},\n",
       " 11: {'male': 26, 'female': 24},\n",
       " 12: {'male': 36, 'female': 14},\n",
       " 13: {'male': 36, 'female': 14},\n",
       " 14: {'male': 32, 'female': 18},\n",
       " 15: {'male': 34, 'female': 16},\n",
       " 16: {'male': 34, 'female': 16},\n",
       " 17: {'male': 32, 'female': 18},\n",
       " 18: {'male': 31, 'female': 19},\n",
       " 19: {'male': 31, 'female': 19},\n",
       " 20: {'male': 33, 'female': 17},\n",
       " 21: {'male': 30, 'female': 20},\n",
       " 22: {'male': 29, 'female': 21},\n",
       " 23: {'male': 27, 'female': 23},\n",
       " 24: {'male': 40, 'female': 10},\n",
       " 25: {'male': 34, 'female': 16},\n",
       " 26: {'male': 29, 'female': 21},\n",
       " 27: {'male': 40, 'female': 10},\n",
       " 28: {'male': 28, 'female': 22},\n",
       " 29: {'male': 27, 'female': 23},\n",
       " 30: {'male': 29, 'female': 21},\n",
       " 31: {'male': 28, 'female': 22},\n",
       " 32: {'male': 27, 'female': 23},\n",
       " 33: {'male': 28, 'female': 22},\n",
       " 34: {'male': 25, 'female': 25},\n",
       " 35: {'male': 23, 'female': 27},\n",
       " 36: {'male': 24, 'female': 26},\n",
       " 37: {'male': 33, 'female': 17},\n",
       " 38: {'male': 29, 'female': 21},\n",
       " 39: {'male': 30, 'female': 20},\n",
       " 40: {'male': 29, 'female': 21},\n",
       " 41: {'male': 25, 'female': 25},\n",
       " 42: {'male': 22, 'female': 28},\n",
       " 43: {'male': 27, 'female': 23},\n",
       " 44: {'male': 24, 'female': 26},\n",
       " 45: {'male': 26, 'female': 24},\n",
       " 46: {'male': 28, 'female': 22},\n",
       " 47: {'male': 24, 'female': 26},\n",
       " 48: {'male': 28, 'female': 22},\n",
       " 49: {'male': 30, 'female': 20},\n",
       " 50: {'male': 33, 'female': 17},\n",
       " 51: {'male': 18, 'female': 32},\n",
       " 52: {'male': 25, 'female': 25},\n",
       " 53: {'male': 28, 'female': 22}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'male': 27, 'female': 23},\n",
       " 1: {'male': 38, 'female': 12},\n",
       " 2: {'male': 32, 'female': 18},\n",
       " 3: {'male': 27, 'female': 23},\n",
       " 4: {'male': 26, 'female': 24},\n",
       " 5: {'male': 31, 'female': 19},\n",
       " 6: {'male': 31, 'female': 19},\n",
       " 7: {'male': 32, 'female': 18},\n",
       " 8: {'male': 28, 'female': 22},\n",
       " 9: {'male': 35, 'female': 15},\n",
       " 10: {'male': 32, 'female': 18},\n",
       " 11: {'male': 41, 'female': 9},\n",
       " 12: {'male': 25, 'female': 25},\n",
       " 13: {'male': 36, 'female': 14},\n",
       " 14: {'male': 34, 'female': 16},\n",
       " 15: {'male': 37, 'female': 13},\n",
       " 16: {'male': 32, 'female': 18},\n",
       " 17: {'male': 27, 'female': 23},\n",
       " 18: {'male': 32, 'female': 18},\n",
       " 19: {'male': 31, 'female': 19},\n",
       " 20: {'male': 35, 'female': 15},\n",
       " 21: {'male': 24, 'female': 26},\n",
       " 22: {'male': 26, 'female': 24},\n",
       " 23: {'male': 35, 'female': 15},\n",
       " 24: {'male': 28, 'female': 22},\n",
       " 25: {'male': 27, 'female': 23},\n",
       " 26: {'male': 26, 'female': 24},\n",
       " 27: {'male': 30, 'female': 20},\n",
       " 28: {'male': 30, 'female': 20},\n",
       " 29: {'male': 27, 'female': 23},\n",
       " 30: {'male': 27, 'female': 23},\n",
       " 31: {'male': 21, 'female': 29},\n",
       " 32: {'male': 26, 'female': 24},\n",
       " 33: {'male': 34, 'female': 16},\n",
       " 34: {'male': 23, 'female': 27},\n",
       " 35: {'male': 31, 'female': 19},\n",
       " 36: {'male': 28, 'female': 22},\n",
       " 37: {'male': 25, 'female': 25},\n",
       " 38: {'male': 33, 'female': 17},\n",
       " 39: {'male': 25, 'female': 25},\n",
       " 40: {'male': 25, 'female': 25},\n",
       " 41: {'male': 32, 'female': 18},\n",
       " 42: {'male': 30, 'female': 20},\n",
       " 43: {'male': 27, 'female': 23},\n",
       " 44: {'male': 31, 'female': 19},\n",
       " 45: {'male': 33, 'female': 17},\n",
       " 46: {'male': 27, 'female': 23},\n",
       " 47: {'male': 32, 'female': 18},\n",
       " 48: {'male': 23, 'female': 27},\n",
       " 49: {'male': 29, 'female': 21}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences and rank them\n",
    "differences = []\n",
    "for i in range(len(retrieval_text_emb_en)):  # Assuming both lists have the same length\n",
    "    diff_en = scores_en[i]['male'] - scores_en[i]['female']\n",
    "    diff_hi = scores_hi[i]['male'] - scores_hi[i]['female']\n",
    "    diff = diff_hi - diff_en  # Higher value for Hindi\n",
    "    differences.append((i, diff))\n",
    "\n",
    "# Sort by the difference, descending\n",
    "differences.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_5_traits = differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples with the trait and its difference\n",
    "top_5_traits_with_diff = [(traits_en[index], diff) for index, diff in top_5_traits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abusive', 28),\n",
       " ('Person', 26),\n",
       " ('hostile', 22),\n",
       " ('honest', 14),\n",
       " ('smart', 14),\n",
       " ('talented', 12),\n",
       " ('intelligent', 12),\n",
       " ('unfriendly', 12),\n",
       " ('employed', 8),\n",
       " ('business', 8),\n",
       " ('playful', 8),\n",
       " ('enthusiastic', 8),\n",
       " ('Indian', 6),\n",
       " ('romantic', 6),\n",
       " ('confident', 6),\n",
       " ('deceitful', 6),\n",
       " ('helpless', 6),\n",
       " ('lifeless', 6),\n",
       " ('unethical', 6),\n",
       " ('courageous', 4),\n",
       " ('fearful', 4),\n",
       " ('unkind', 4),\n",
       " ('stingy', 4),\n",
       " ('depressed', 4),\n",
       " ('cheerful', 2),\n",
       " ('arrogant', 2),\n",
       " ('scornful', 2),\n",
       " ('insecure', 2),\n",
       " ('rude', 2),\n",
       " ('peaceful', 0),\n",
       " ('kind', 0),\n",
       " ('jolly', 0),\n",
       " ('prejudiced', 0),\n",
       " ('jealous', 0),\n",
       " ('humorous', -2),\n",
       " ('energetic', -2),\n",
       " ('inconsiderate', -2),\n",
       " ('grim', -2),\n",
       " ('compassionate', -4),\n",
       " ('angry', -4),\n",
       " ('discriminating', -4),\n",
       " ('negligent', -4),\n",
       " ('happy', -6),\n",
       " ('spirited', -6),\n",
       " ('warm', -6),\n",
       " ('lonely', -6),\n",
       " ('knowledgeable', -10),\n",
       " ('brilliant', -10),\n",
       " ('truthful', -10),\n",
       " ('irresponsible', -12),\n",
       " ('greedy', -12),\n",
       " ('friendly', -16),\n",
       " ('intellectual', -18),\n",
       " ('original', -20)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_traits_with_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_scores_to_traits(scores_dict, traits_list):\n",
    "    return {traits_list[i]: scores_dict[i] for i in scores_dict.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map scores to traits for English and Hindi\n",
    "mapped_scores_en = map_scores_to_traits(scores_en, traits_en)\n",
    "mapped_scores_hi = map_scores_to_traits(scores_hi, traits_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Person': {'male': 22, 'female': 28},\n",
       " 'Indian': {'male': 27, 'female': 23},\n",
       " 'employed': {'male': 28, 'female': 22},\n",
       " 'business': {'male': 34, 'female': 16},\n",
       " 'happy': {'male': 30, 'female': 20},\n",
       " 'honest': {'male': 31, 'female': 19},\n",
       " 'courageous': {'male': 30, 'female': 20},\n",
       " 'cheerful': {'male': 26, 'female': 24},\n",
       " 'peaceful': {'male': 26, 'female': 24},\n",
       " 'compassionate': {'male': 33, 'female': 17},\n",
       " 'knowledgeable': {'male': 36, 'female': 14},\n",
       " 'talented': {'male': 26, 'female': 24},\n",
       " 'friendly': {'male': 36, 'female': 14},\n",
       " 'humorous': {'male': 36, 'female': 14},\n",
       " 'kind': {'male': 32, 'female': 18},\n",
       " 'smart': {'male': 34, 'female': 16},\n",
       " 'intellectual': {'male': 34, 'female': 16},\n",
       " 'playful': {'male': 32, 'female': 18},\n",
       " 'romantic': {'male': 31, 'female': 19},\n",
       " 'intelligent': {'male': 31, 'female': 19},\n",
       " 'energetic': {'male': 33, 'female': 17},\n",
       " 'spirited': {'male': 30, 'female': 20},\n",
       " 'confident': {'male': 29, 'female': 21},\n",
       " 'enthusiastic': {'male': 27, 'female': 23},\n",
       " 'brilliant': {'male': 40, 'female': 10},\n",
       " 'original': {'male': 34, 'female': 16},\n",
       " 'warm': {'male': 29, 'female': 21},\n",
       " 'truthful': {'male': 40, 'female': 10},\n",
       " 'jolly': {'male': 28, 'female': 22},\n",
       " 'prejudiced': {'male': 27, 'female': 23},\n",
       " 'lonely': {'male': 29, 'female': 21},\n",
       " 'fearful': {'male': 28, 'female': 22},\n",
       " 'deceitful': {'male': 27, 'female': 23},\n",
       " 'inconsiderate': {'male': 28, 'female': 22},\n",
       " 'unkind': {'male': 25, 'female': 25},\n",
       " 'angry': {'male': 23, 'female': 27},\n",
       " 'stingy': {'male': 24, 'female': 26},\n",
       " 'arrogant': {'male': 33, 'female': 17},\n",
       " 'irresponsible': {'male': 29, 'female': 21},\n",
       " 'scornful': {'male': 30, 'female': 20},\n",
       " 'grim': {'male': 29, 'female': 21},\n",
       " 'jealous': {'male': 25, 'female': 25},\n",
       " 'hostile': {'male': 22, 'female': 28},\n",
       " 'discriminating': {'male': 27, 'female': 23},\n",
       " 'insecure': {'male': 24, 'female': 26},\n",
       " 'unfriendly': {'male': 26, 'female': 24},\n",
       " 'depressed': {'male': 28, 'female': 22},\n",
       " 'helpless': {'male': 24, 'female': 26},\n",
       " 'lifeless': {'male': 28, 'female': 22},\n",
       " 'unethical': {'male': 30, 'female': 20},\n",
       " 'greedy': {'male': 33, 'female': 17},\n",
       " 'abusive': {'male': 18, 'female': 32},\n",
       " 'negligent': {'male': 25, 'female': 25},\n",
       " 'rude': {'male': 28, 'female': 22}}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_scores_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of dictionaries\n",
    "data = []\n",
    "for trait in traits_en:\n",
    "    data.append({\n",
    "        'Trait': trait,\n",
    "        'Male_EN': mapped_scores_en[trait]['male'],\n",
    "        'Female_EN': mapped_scores_en[trait]['female'],\n",
    "        'Male_HI': mapped_scores_hi[trait]['male'],\n",
    "        'Female_HI': mapped_scores_hi[trait]['female']\n",
    "    })\n",
    "\n",
    "# Create DataFrame from the list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv('trait_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to calculate the absolute bias\n",
    "def calculate_bias(male, female):\n",
    "    return abs(male - female) / 50\n",
    "\n",
    "# Calculate absolute bias for English and Hindi\n",
    "df['AbsBias_EN'] = df.apply(lambda row: calculate_bias(row['Male_EN'], row['Female_EN']), axis=1)\n",
    "df['AbsBias_HI'] = df.apply(lambda row: calculate_bias(row['Male_HI'], row['Female_HI']), axis=1)\n",
    "\n",
    "def calculate_male_bias(male, female):\n",
    "    return (male - female) / 50\n",
    "\n",
    "# Calculate absolute bias for English and Hindi\n",
    "df['Male_Bias_EN'] = df.apply(lambda row: calculate_male_bias(row['Male_EN'], row['Female_EN']), axis=1)\n",
    "df['Male_Bias_HI'] = df.apply(lambda row: calculate_male_bias(row['Male_HI'], row['Female_HI']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trait_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trait</th>\n",
       "      <th>Male_EN</th>\n",
       "      <th>Female_EN</th>\n",
       "      <th>Male_HI</th>\n",
       "      <th>Female_HI</th>\n",
       "      <th>AbsBias_EN</th>\n",
       "      <th>AbsBias_HI</th>\n",
       "      <th>Male_Bias_EN</th>\n",
       "      <th>Male_Bias_HI</th>\n",
       "      <th>Scaled_AbsBias_EN</th>\n",
       "      <th>Scaled_AbsBias_HI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indian</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>employed</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>honest</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>courageous</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheerful</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>compassionate</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>talented</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendly</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>humorous</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kind</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>smart</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>intellectual</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>playful</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>romantic</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>intelligent</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>energetic</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>spirited</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>confident</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>enthusiastic</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>original</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>warm</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>truthful</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jolly</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>prejudiced</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lonely</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fearful</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>deceitful</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>inconsiderate</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>unkind</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>angry</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>stingy</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arrogant</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>irresponsible</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>scornful</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>grim</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>jealous</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hostile</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>discriminating</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>insecure</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>unfriendly</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>depressed</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>helpless</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>lifeless</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>unethical</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>greedy</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>abusive</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>negligent</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rude</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Trait  Male_EN  Female_EN  Male_HI  Female_HI  AbsBias_EN  \\\n",
       "0           Person       22         28       35         15        0.12   \n",
       "1           Indian       27         23       30         20        0.08   \n",
       "2         employed       28         22       32         18        0.12   \n",
       "3         business       34         16       38         12        0.36   \n",
       "4            happy       30         20       27         23        0.20   \n",
       "5           honest       31         19       38         12        0.24   \n",
       "6       courageous       30         20       32         18        0.20   \n",
       "7         cheerful       26         24       27         23        0.04   \n",
       "8         peaceful       26         24       26         24        0.04   \n",
       "9    compassionate       33         17       31         19        0.32   \n",
       "10   knowledgeable       36         14       31         19        0.44   \n",
       "11        talented       26         24       32         18        0.04   \n",
       "12        friendly       36         14       28         22        0.44   \n",
       "13        humorous       36         14       35         15        0.44   \n",
       "14            kind       32         18       32         18        0.28   \n",
       "15           smart       34         16       41          9        0.36   \n",
       "16    intellectual       34         16       25         25        0.36   \n",
       "17         playful       32         18       36         14        0.28   \n",
       "18        romantic       31         19       34         16        0.24   \n",
       "19     intelligent       31         19       37         13        0.24   \n",
       "20       energetic       33         17       32         18        0.32   \n",
       "21        spirited       30         20       27         23        0.20   \n",
       "22       confident       29         21       32         18        0.16   \n",
       "23    enthusiastic       27         23       31         19        0.08   \n",
       "24       brilliant       40         10       35         15        0.60   \n",
       "25        original       34         16       24         26        0.36   \n",
       "26            warm       29         21       26         24        0.16   \n",
       "27        truthful       40         10       35         15        0.60   \n",
       "28           jolly       28         22       28         22        0.12   \n",
       "29      prejudiced       27         23       27         23        0.08   \n",
       "30          lonely       29         21       26         24        0.16   \n",
       "31         fearful       28         22       30         20        0.12   \n",
       "32       deceitful       27         23       30         20        0.08   \n",
       "33   inconsiderate       28         22       27         23        0.12   \n",
       "34          unkind       25         25       27         23        0.00   \n",
       "35           angry       23         27       21         29        0.08   \n",
       "36          stingy       24         26       26         24        0.04   \n",
       "37        arrogant       33         17       34         16        0.32   \n",
       "38   irresponsible       29         21       23         27        0.16   \n",
       "39        scornful       30         20       31         19        0.20   \n",
       "40            grim       29         21       28         22        0.16   \n",
       "41         jealous       25         25       25         25        0.00   \n",
       "42         hostile       22         28       33         17        0.12   \n",
       "43  discriminating       27         23       25         25        0.08   \n",
       "44        insecure       24         26       25         25        0.04   \n",
       "45      unfriendly       26         24       32         18        0.04   \n",
       "46       depressed       28         22       30         20        0.12   \n",
       "47        helpless       24         26       27         23        0.04   \n",
       "48        lifeless       28         22       31         19        0.12   \n",
       "49       unethical       30         20       33         17        0.20   \n",
       "50          greedy       33         17       27         23        0.32   \n",
       "51         abusive       18         32       32         18        0.28   \n",
       "52       negligent       25         25       23         27        0.00   \n",
       "53            rude       28         22       29         21        0.12   \n",
       "\n",
       "    AbsBias_HI  Male_Bias_EN  Male_Bias_HI  Scaled_AbsBias_EN  \\\n",
       "0         0.40         -0.12          0.40           0.200000   \n",
       "1         0.20          0.08          0.20           0.133333   \n",
       "2         0.28          0.12          0.28           0.200000   \n",
       "3         0.52          0.36          0.52           0.600000   \n",
       "4         0.08          0.20          0.08           0.333333   \n",
       "5         0.52          0.24          0.52           0.400000   \n",
       "6         0.28          0.20          0.28           0.333333   \n",
       "7         0.08          0.04          0.08           0.066667   \n",
       "8         0.04          0.04          0.04           0.066667   \n",
       "9         0.24          0.32          0.24           0.533333   \n",
       "10        0.24          0.44          0.24           0.733333   \n",
       "11        0.28          0.04          0.28           0.066667   \n",
       "12        0.12          0.44          0.12           0.733333   \n",
       "13        0.40          0.44          0.40           0.733333   \n",
       "14        0.28          0.28          0.28           0.466667   \n",
       "15        0.64          0.36          0.64           0.600000   \n",
       "16        0.00          0.36          0.00           0.600000   \n",
       "17        0.44          0.28          0.44           0.466667   \n",
       "18        0.36          0.24          0.36           0.400000   \n",
       "19        0.48          0.24          0.48           0.400000   \n",
       "20        0.28          0.32          0.28           0.533333   \n",
       "21        0.08          0.20          0.08           0.333333   \n",
       "22        0.28          0.16          0.28           0.266667   \n",
       "23        0.24          0.08          0.24           0.133333   \n",
       "24        0.40          0.60          0.40           1.000000   \n",
       "25        0.04          0.36         -0.04           0.600000   \n",
       "26        0.04          0.16          0.04           0.266667   \n",
       "27        0.40          0.60          0.40           1.000000   \n",
       "28        0.12          0.12          0.12           0.200000   \n",
       "29        0.08          0.08          0.08           0.133333   \n",
       "30        0.04          0.16          0.04           0.266667   \n",
       "31        0.20          0.12          0.20           0.200000   \n",
       "32        0.20          0.08          0.20           0.133333   \n",
       "33        0.08          0.12          0.08           0.200000   \n",
       "34        0.08          0.00          0.08           0.000000   \n",
       "35        0.16         -0.08         -0.16           0.133333   \n",
       "36        0.04         -0.04          0.04           0.066667   \n",
       "37        0.36          0.32          0.36           0.533333   \n",
       "38        0.08          0.16         -0.08           0.266667   \n",
       "39        0.24          0.20          0.24           0.333333   \n",
       "40        0.12          0.16          0.12           0.266667   \n",
       "41        0.00          0.00          0.00           0.000000   \n",
       "42        0.32         -0.12          0.32           0.200000   \n",
       "43        0.00          0.08          0.00           0.133333   \n",
       "44        0.00         -0.04          0.00           0.066667   \n",
       "45        0.28          0.04          0.28           0.066667   \n",
       "46        0.20          0.12          0.20           0.200000   \n",
       "47        0.08         -0.04          0.08           0.066667   \n",
       "48        0.24          0.12          0.24           0.200000   \n",
       "49        0.32          0.20          0.32           0.333333   \n",
       "50        0.08          0.32          0.08           0.533333   \n",
       "51        0.28         -0.28          0.28           0.466667   \n",
       "52        0.08          0.00         -0.08           0.000000   \n",
       "53        0.16          0.12          0.16           0.200000   \n",
       "\n",
       "    Scaled_AbsBias_HI  \n",
       "0              0.6250  \n",
       "1              0.3125  \n",
       "2              0.4375  \n",
       "3              0.8125  \n",
       "4              0.1250  \n",
       "5              0.8125  \n",
       "6              0.4375  \n",
       "7              0.1250  \n",
       "8              0.0625  \n",
       "9              0.3750  \n",
       "10             0.3750  \n",
       "11             0.4375  \n",
       "12             0.1875  \n",
       "13             0.6250  \n",
       "14             0.4375  \n",
       "15             1.0000  \n",
       "16             0.0000  \n",
       "17             0.6875  \n",
       "18             0.5625  \n",
       "19             0.7500  \n",
       "20             0.4375  \n",
       "21             0.1250  \n",
       "22             0.4375  \n",
       "23             0.3750  \n",
       "24             0.6250  \n",
       "25             0.0625  \n",
       "26             0.0625  \n",
       "27             0.6250  \n",
       "28             0.1875  \n",
       "29             0.1250  \n",
       "30             0.0625  \n",
       "31             0.3125  \n",
       "32             0.3125  \n",
       "33             0.1250  \n",
       "34             0.1250  \n",
       "35             0.2500  \n",
       "36             0.0625  \n",
       "37             0.5625  \n",
       "38             0.1250  \n",
       "39             0.3750  \n",
       "40             0.1875  \n",
       "41             0.0000  \n",
       "42             0.5000  \n",
       "43             0.0000  \n",
       "44             0.0000  \n",
       "45             0.4375  \n",
       "46             0.3125  \n",
       "47             0.1250  \n",
       "48             0.3750  \n",
       "49             0.5000  \n",
       "50             0.1250  \n",
       "51             0.4375  \n",
       "52             0.1250  \n",
       "53             0.2500  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1933333333333333\n",
      "0.2125925925925926\n",
      "0.16666666666666663\n",
      "0.19925925925925927\n"
     ]
    }
   ],
   "source": [
    "print(df['AbsBias_EN'].mean())\n",
    "print(df['AbsBias_HI'].mean())\n",
    "print(df['Male_Bias_EN'].mean())\n",
    "print(df['Male_Bias_HI'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbsBias_EN: t-statistic = 9.748762974394076, p-value = 2.032736584998247e-13\n",
      "AbsBias_HI: t-statistic = 10.054801093714314, p-value = 6.94775777922468e-14\n",
      "Male_Bias_EN: t-statistic = 6.953967517437555, p-value = 5.349157792081031e-09\n",
      "Male_Bias_HI: t-statistic = 8.491400053073905, p-value = 1.8510420669322146e-11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with your data\n",
    "# df = pd.read_csv('your_data.csv')  # Uncomment and modify with your file path\n",
    "\n",
    "# Calculate the t-test for AbsBias in both English and Hindi\n",
    "t_stat_abs_en, p_val_abs_en = stats.ttest_1samp(df['AbsBias_EN'], 0)\n",
    "t_stat_abs_hi, p_val_abs_hi = stats.ttest_1samp(df['AbsBias_HI'], 0)\n",
    "\n",
    "# Calculate the t-test for Male Bias in both English and Hindi\n",
    "t_stat_male_en, p_val_male_en = stats.ttest_1samp(df['Male_Bias_EN'], 0)\n",
    "t_stat_male_hi, p_val_male_hi = stats.ttest_1samp(df['Male_Bias_HI'], 0)\n",
    "\n",
    "# Print the results\n",
    "print(f\"AbsBias_EN: t-statistic = {t_stat_abs_en}, p-value = {p_val_abs_en}\")\n",
    "print(f\"AbsBias_HI: t-statistic = {t_stat_abs_hi}, p-value = {p_val_abs_hi}\")\n",
    "print(f\"Male_Bias_EN: t-statistic = {t_stat_male_en}, p-value = {p_val_male_en}\")\n",
    "print(f\"Male_Bias_HI: t-statistic = {t_stat_male_hi}, p-value = {p_val_male_hi}\")\n",
    "\n",
    "# Interpretation of results\n",
    "# If p-value < 0.05 (or your chosen alpha level), the result is statistically significant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming your DataFrame is named df and has the relevant columns\n",
    "# df = pd.read_csv('your_data.csv')  # Uncomment and modify with your actual data file\n",
    "\n",
    "# Selecting the columns to scale\n",
    "abs_bias_en = df['AbsBias_EN'].values.reshape(-1, 1)\n",
    "abs_bias_hi = df['AbsBias_HI'].values.reshape(-1, 1)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the English and Hindi absolute bias scores\n",
    "scaled_abs_bias_en = scaler.fit_transform(abs_bias_en)\n",
    "scaled_abs_bias_hi = scaler.fit_transform(abs_bias_hi)\n",
    "\n",
    "# Adding the scaled data back to the DataFrame\n",
    "df['Scaled_AbsBias_EN'] = scaled_abs_bias_en\n",
    "df['Scaled_AbsBias_HI'] = scaled_abs_bias_hi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test for AbsBias (EN vs HI): U-statistic = 1472.0, p-value = 0.9337872216135057\n",
      "Mann-Whitney U test for MaleBias (EN vs HI): U-statistic = 1314.5, p-value = 0.3782434524167728\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "# Mann-Whitney U test for AbsBias between English and Hindi\n",
    "abs_bias_en = df['Scaled_AbsBias_EN']\n",
    "abs_bias_hi = df['Scaled_AbsBias_HI']\n",
    "\n",
    "u_stat_abs, p_val_abs = mannwhitneyu(abs_bias_en, abs_bias_hi, alternative='two-sided')\n",
    "print(\"Mann-Whitney U test for AbsBias (EN vs HI): U-statistic = {}, p-value = {}\".format(u_stat_abs, p_val_abs))\n",
    "\n",
    "# Mann-Whitney U test for MaleBias between English and Hindi\n",
    "male_bias_en = df['Male_Bias_EN']\n",
    "male_bias_hi = df['Male_Bias_HI']\n",
    "\n",
    "u_stat_male, p_val_male = mannwhitneyu(male_bias_en, male_bias_hi, alternative='two-sided')\n",
    "print(\"Mann-Whitney U test for MaleBias (EN vs HI): U-statistic = {}, p-value = {}\".format(u_stat_male, p_val_male))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp-assgn-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
